---
title: "Lecture 18: Autoregressive models: CAR and SAR"
output:
  revealjs::revealjs_presentation:
    theme: white
    center: true
    transition: none
    incremental: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(message = FALSE)
library(dplyr)
library(ggplot2)
library(leaflet)
library(readr)
library(geojsonio)
```

# Class Intro

## Intro Questions 
- Given an areal data set, describe the process for determining whether spatial patterns are present.

- For Today:
    - Smoothing and Autoregressive Models


# Spatial Smoothing

## Smoothing
- Spatial smoothing results in a "smoother" spatial surface, by sharing information from across the neighborhood structure.

- One option is replacing $Y_i$ with
$$\hat{Y_i} = \sum_j w_{ij}Y_j / w_{i+},$$
where $w_{i+} = \sum_j w_{ij}$.

- What are some pros and cons of this smoother?

## "Exponential" smoother

- Another option would be to use:
$$\hat{Y}_i^* = (1 - \alpha) Y_i + \hat{Y}_i$$
- Compare $\hat{Y}_i^*$ with $\hat{Y}_i$.

- What is the impact of $\alpha?$

- This is essentially the exponential smoother from time series.

- More details about smoothing (or shrinkage) will be discussed from a model-based framework.

# Brook's Lemma and Markov Random Fields

## Brook's Lemma

- To consider areal data from a model-based perspective, it is necessary to obtain the joint distribution of the responses 
$$p(y_1, \dots, y_n).$$
- From the joint distribution, the  *full conditional distribution*
$$p(y_i|y_j, j \neq i),$$
is uniquely determined.
- Brook's Lemma states that the joint distribution can be obtained from the full conditional distributions.

## Large Areal Data Sets
- When the areal data set is large, working with the full conditional distributions can be preferred to the full joint distribution.
- More specifically, the response $Y_i$ should only directly depend on the neighbors, hence,
$$p(y_i|y_j, j \neq i) = p(y_i|y_j, j \in \delta_i)$$
where $\delta_i$ denotes the neighborhood around $i$.

## Markov Random Field 

- The idea of using the local specification for determining the global form of the distribution is Markov random field.
- An essential element of a MRF is a *clique*, which is a group of units where each unit is a neighbor of all units in the clique
- A *potential function* is a function that is exchangeable in the arguments.
- With continuous data a common potential is $(Y_i - Y_j)^2$ if $i \sim j$ ($i$ is a neighbor of $j$).

## Gibbs Distribution

- A joint distribution $p(y_1, \dots, y_n)$ is a Gibbs distribution if it is a function of $Y_i$ only through the potential on cliques.

- Mathematically, this can be expressed as:
$$p(y_1, \dots, y_n) \propto \exp \left(\gamma \sum_k \sum_{\alpha \in \mathcal{M}_k} \phi^{(k)}(y_{\alpha_1},y_{\alpha_2}, \dots, y_{\alpha_k} ) \right),$$
where $\phi^{(k)}$ is a potential of order $k$, $\mathcal{M}_k$ is the collection of all subsets of size $k = {1, 2, ...}$(typically restricted to 2 in spatial settings), $\alpha$ indexes the set in $\mathcal{M}_k$.

## Hammersley-CLifford Theorem

- The Hammersley-Clifford Theorem demonstrates that if we have a MRF that defines a unique joint distribution, then that joint distribution is a Gibbs distribution.
- The converse was later proved, showing that a MRF could be sampled from the associated Gibbs distribution (origination of Gibbs sampler).

## Model Specification

- With continuous data, a common choice for the joint distribution is the pairwise difference
$$p(y_1, \dots, y_n) \propto \exp \left(-\frac{1}{2\tau^2} \sum_{i,j}(y_i - y_j)^2 I(i \sim j) \right)$$
- Then the full conditional distributions can be written as
$$p(y_i|y_j, j \neq i) = N \left(\sum_{j \in \delta_i} y_i / m_i, \tau^2 / m_i \right)$$
where $m_i$ are the number of neighbors for unit $i$.
- This results in a spatial smoother, where the mean of a response is the average of the neighbors.

# Conditional Autoregressive Models

## Gaussian Model

- Suppose the full conditionals are specifed as
$$Y_i|y_j, j\neq i \sim N \left(\sum_j b_{ij} y_j, \tau_i^2 \right)$$
- Then using Brooks' Lemma, the joint distribution is
$$p(y_1, \dots, y_n) \propto \exp \left(-\frac{1}{2}\boldsymbol{y}^T D^{-1} (I - B) \boldsymbol{y} \right),$$
where $B$ is a matrix with entries $b_{ij}$ and D is a diagonal matrix with diagonal elements $D_{ii} = \tau_i^2$.

## Gaussian Model

- The previous equation suggests a multivariate normal distribution, but $D^{-1}(I - B)$ should be symmetric.

- Symmetry requires $$\frac{b_{ij}}{\tau^2_i}=\frac{b_{ji}}{\tau^2_j}, \; \; \forall \; \; i , j$$

- In general, $B$ is not symmetric, but setting $b_{ij} = w_{ij}/ w_{i+}$ and $\tau_i^2 = \tau^2 / w_{i+}$ satisfies the symmetry assumptions (given that we assume W is symmetric)

## Gaussian Model
- Now the full conditional distribution can be written as
$$Y_i|y_j, j\neq i \sim N \left(\sum_j w_{ij} y_j / w_{i+}, \tau^2 / w_{i+} \right)$$

- Similarly the joint distribution is now
$$p(y_1, \dots, y_n) \propto \exp \left(-\frac{1}{2 \tau^2}\boldsymbol{y}^T  (D_w - W) \boldsymbol{y} \right)$$
where $D_w$ is a diagonal matrix with diagonal entries $(D_w)_{ii} = w_{i+}$ 

## Gaussian Model
- The joint distribution can also be re-written as
$$p(y_1, \dots, y_n) \propto \exp \left(-\frac{1}{2 \tau^2} \sum_{i \neq j} w_{ij} (y_i - y_j)^2\right)$$

- However, both these formulations results in an improper distribution. This could be solved with a constraint, such as $Y_i = 0$.

- The result is the joint distribution is improper, despite proper full conditional distributions. This model specification is often referred to as an *intrinsically autoregressive* model (IAR).

## IAR

- The IAR cannot be used to model data directly, rather this is used a prior specification and attached to random effects specified at the second stage of the hierarchical model.

- The impropriety can be remedied by defining a parameter $\rho$ such that $(D_w - W)$ becomes $(D_w - \rho W)$ such that this matrix is nonsingular.

- The parameter $\rho$ can be considered an extra parameter in the CAR model.

## Posterior Distribution

- With or without $\rho,$ $p(\boldsymbol{y})$ (or the Bayesian posterior when the CAR specification is placed on the spatial random effects) is proper.

- When using $\rho$, the full conditional becomes $$Y_i|y_j, j\neq i \sim N \left(\rho \sum_j w_{ij} y_j / w_{i+}, \tau^2 / w_{i+} \right)$$

- The authors state, "we do not take a position with regard to propriety or impropriety in employing CAR specifications"

## Alternative Specification

- Alternatively, the model can be re-written as 
\begin{eqnarray*}
\boldsymbol{Y} &=& B \boldsymbol{Y} + \boldsymbol{\epsilon} \\
(I - B)\boldsymbol{Y} &=&  \boldsymbol{\epsilon}
\end{eqnarray*}

- Hence, the distribution for $\boldsymbol{Y}$ induces a distribution for $\boldsymbol{\epsilon}$.

# Simultaneous Autoregression Model

## Simultaneous Autoregression Model

- Rather than specifying the distribution on $\boldsymbol{Y}$, as in the CAR specification, the distribution can be specified for $\boldsymbol{\epsilon}$ which induces a distribution for $\boldsymbol{Y}$.

- Let $\boldsymbol{\epsilon} \sim N(\boldsymbol{0}, \tilde{D})$, where $\tilde{D}$ is a diagonal matrix with elements $(\tilde{D})_{ii} = \sigma^2_i$.

- Now $Y_i = \sum_j b_{ij} Y_j + \epsilon_i$ or equivalently $(I-B)\boldsymbol{Y} = \boldsymbol{\epsilon}$.

## SAR Model

- If the matrix $(I - B)$ is full rank, then 
$$\boldsymbol{Y} \sim N \left(\boldsymbol{0},(I - B)^{-1} \tilde{D} ((I - B)^{-1})^T \right)$$
- If $\tilde{D} = \sigma^2 I$, then $\boldsymbol{Y} \sim N \left(\boldsymbol{0},\sigma^2 \left[(I - B)  (I - B)^T \right]^{-1} \right)$

## Choosing B

There are two common approaches for choosing B

1. $B = \rho W,$ where $W$ is a contiguity matrix with entries 1 and 0. The parameter $\rho$ is called the spatial autoregression parameter.

2. $B = \alpha \tilde{W}$ where $(\tilde{W})_{ij} = w_{ij} / w_{i+}.$ The $\alpha$ parameter is called the spatial autocorrelation parameter.

## SAR Model for Regression

- SAR Models are often introduced in a regression context, where the residuals $(\boldsymbol{U})$ follow a SAR model.

- Let $\boldsymbol{U} = \boldsymbol{Y} - X \boldsymbol{\beta}$ and then $\boldsymbol{U} = B \boldsymbol{U} + \boldsymbol{\epsilon}$ which results in
$$\boldsymbol{Y} = B \boldsymbol{Y} + (I-B) X \boldsymbol{\beta} + \boldsymbol{\epsilon}$$

- Hence the model contains a spatial weighting of neighbors $(B \boldsymbol{Y})$ and a regression component $((I-B) X \boldsymbol{\beta} )$.

- What is the result of extreme cases for $B = 0$ or $B = I$.

## Other Notes

- The SAR specification is not typically used in a GLM setting.

- SAR models are well suited for maximum likelihood

- Without specifying a hierarchical form, Bayesian sampling of random effects is more difficult than the CAR specification.

# Areal Data Models

## Disease Mapping

- Areal data with counts is often associated with disease mapping, where there are two quantities for each areal unit:
\begin{eqnarray*}
Y_i &=& \text{ observed number of cases of disease in county i }\\
E_i &=& \text{ expected number of cases of disease in county i}
\end{eqnarray*}

## Expected Counts

- One way to think about the expected counts is
$$E_i = n_i \bar{r} = n_i \left(\frac{\sum_i y_i}{\sum_i n_i}  \right),$$
where $\bar{r}$ is the overall disease rate and $n_i$ is the population for region $i$.

- However note that $\bar{r},$  and hence, $E_i$ is a not fixed, but is a function of the data. This is called *internal standardization*.

- An alternative is to use some standard rate for a given age group, such that $E_i = \sum_j n_{ij} r_j.$ This is *external standardization.*

## Traditional Models

- Often counts are assumed to follow the Poisson model where
$$Y_i|\eta_i \sim Poisson(E_i \eta_i),$$
where $\eta_i$ is teh relative risk of the disease in region $i$.

- Then the MLE of $\eta_i$ is $\frac{Y_i}{E_i}$. This quantity is known as the *standardized morbidity ratio* (SMR).

## Poisson-Gamma Model

- Consider the following framework
\begin{eqnarray*}
Y_i | \eta_i &\sim& Po(E_i \eta_i), \text{ i = 1, \dots, I}\\
\eta_i &\sim& Gamma(a,b),
\end{eqnarray*}
where the gamma distribution has mean $\frac{a}{b}$ and variance is $\frac{a}{b^2}$.

- This can be reparameterized such that $a = \frac{\mu^2}{\sigma^2}$ and $b = \frac{\mu}{\sigma^2}$.

## Poisson-Gamma Conjugacy
- For the Poisson sampling model, the gamma prior is conjugate. This means that the posterior distribution $p(\eta_i | y_i)$ is also a gamma distribution.

- In particular the posterior distribution $p(\eta_i|y_i)$ is $Gamma(y_i + a, E_i + b)$.


## Bayesian Point Estimate
- The mean of this distribution is
\begin{eqnarray*}
E(\eta_i | \boldsymbol{y}) = E(\eta_i| y_i) &=& \frac{y_i + a}{E_i + b} = \frac{y_i + \frac{\mu^2}{\sigma^2}}{E_i + \frac{\mu}{\sigma^2}}\\
&=& \frac{E_i (\frac{y_i}{E_i})}{E_i + \frac{\mu}{\sigma^2}} + \frac{(\frac{\mu}{\sigma^2})\mu}{E_i + \frac{\mu}{\sigma2}}\\
&=& w_i SMR_i + (1 - w_i) \mu,
\end{eqnarray*}
where $w_i = \frac{E_i}{E_i + (\mu / \sigma^2)}$

- Thus the point estimate is a weighted average of the data-based SMR for region $i$ and the prior mean $\mu$.



## Poisson-lognormal models

- Unfortunately the Poisson-gamma framework does not easily permit spatial structure with the $\eta_i$ and a univariate gamma distribution. 

- A relatively new option is to use the [multivariate-log gamma distribution](https://arxiv.org/pdf/1512.07273.pdf) as the prior.

- A common alternative is to use the Poisson-lognormal model.

## Poisson-lognormal models

The model can be written as 
\begin{eqnarray*}
Y_i | \psi_i &\sim& Poisson(E_i \exp(\psi_i))\\
\psi_i &=& \boldsymbol{x_i^T}\boldsymbol{\beta} + \theta_i + \phi_i
\end{eqnarray*}

where $\boldsymbol{x_i}$ are spatial covariates, $\theta_i$ corresponds to region wide heterogeneity, and $\psi_i$ captures local clustering.

## Data Simulation Exercise

Simulate and visualize data following the Poisson-gamma framework and the Poisson-lognormal models.